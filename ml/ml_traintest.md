---
layout: default
---

# 机器学习训练框架有关内容
## 0 .数据预处理有关
## 1. 数据样本划分Train-Test-Validation，交叉验证等
这部分李航书里讲的很快阿，默认我们都会，所以这部分参考的周志华的瓜书。 <br>
### 1.1 数据集划分
对于数据集合S，一般划分为训练集、验证集和测试集。训练集用于训练模型，验证集用于调整模型的超参数，测试集用于评估模型的泛化能力。 <br>
### 1.2 交叉验证
交叉验证是一种评估模型性能的方法。 <br> 
**K折交叉验证**：将数据集划分为k个子集，每次用k-1个子集训练模型，剩下的子集用于测试模型，重复k次，最后取k次的平均值作为模型的性能指标。 <br>
**留一交叉验证**：将数据集划分为1个元素的测试集和剩余元素组成的训练集，常用于数据不足的情况。 <br>
**有放回的构建测试集** 这个是瓜书里提到的，就是每次从N个数据的数据集中有放回的抽取一个样本，构建测试集，剩下的作为训练集，重复N次。那么**一个样本没被抽到的概率是$(1-\frac{1}{N})^N$，当N趋于无穷时，这个概率趋于$\frac{1}{e}$**，即63.2%。 <br>
* 可能问
## 2. 常见损失函数，梯度下降具体流程
前三个0-1损失，交叉熵损失和对数似然损失是classification问题中常见的损失函数。平方误差损失、和绝对值误差是regression问题中常见的损失函数。关于pytorch中如何实现这些损失函数，可以参考[这里](https://blog.csdn.net/ganxiwu9686/article/details/103207509)。
### 2.1 0-1损失函数
0-1损失函数：$L(Y,f(X)) = I(Y \neq f(X))$ <br>
**0-1损失函数不可导**，因此在分类中更多使用交叉熵损失函数。 <br>
* 可能会问0-1损失和交叉熵损失关系：0-1是交叉熵在二分类问题的特例。
* 可能问对于多分类问题怎么处理，可以用交叉熵损失函数。
### 2.2 交叉熵损失函数
交叉熵损失函数：$L(Y,P) = -\sum_{i}Y_i \log P_i$ <br>
交叉熵损失函数是基于信息论的，用于衡量两个概率分布之间的差异。香农说：“信息消除的不确定性越大说明信息的量越大。”对于一个事件x，其信息量为：$I(x) = -\log P(x)$，其中$P(x)$为事件x发生的概率。因此交叉熵损失可以看作是所有信息的信息量的加权和，即信息的期望: $H(x) = -\sum_{i}P(x_i) \log P(x_i)$。  <br>
在分类问题中，$Y$为真实标签，$P$为预测标签的概率分布。 交叉损失函数可以处理**多分类问题**，且可导，因此在分类问题中更常用。 
* 关于相对熵（KL散度）和交叉熵的关系，若关于某随机变量x有两个概率分布P(x)和Q(x)，其中P(x)为真实分布，Q(x)为预测分布，则：
* $D_{KL}(P||Q) = \sum_{i}P(x_i) \log \frac{P(x_i)}{Q(x_i)} = \sum_{i}P(x_i) \log P(x_i) - \sum_{i}P(x_i) \log Q(x_i) = H(P,Q) - H(P)$
* 即**相对熵等于交叉熵减去真实分布的信息熵，KL散度用于衡量两个分布之间的差异**。可能强化学习问PPO的时候会问到。这里补一下
### 2.3 对数(似然)损失函数
对数似然损失函数：$L(Y,P) = -\sum_{i}Y_i \log P_i - (1-Y_i) \log (1-P_i)$ <br>
对于二分类问题，对数似然损失函数和交叉熵损失函数一样。没什么好说的，问到不会可以重开了。
* 这边可能会让手推对数似然函数下，经验风险最小化和极大似然关系等价，即**李航习题1.2**，简单思路如下：
* 经验风险最小化：$R_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i))$，其中L为对数似然损失函数，N为样本数。
* 带入对数似然损失函数：$R_{emp}(f) = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log f(x_i) + (1-y_i) \log (1-f(x_i))]$，这就是经验风险最小化的表达式。
* 极大似然估计：$L(\theta) = \sum_{i=1}^{N} \log P(y_i|x_i;\theta)$，其中P为条件概率分布，$\theta$为参数。
* 带入对数似然损失函数：$L(\theta) = \sum_{i=1}^{N} [y_i \log f(x_i) + (1-y_i) \log (1-f(x_i))]$，这就是极大似然估计的表达式。
### 2.4 平方误差损失函数
平方误差损失函数：$L(Y,f(X)) = \frac{1}{2N} \sum_{i}(Y_i - f(X_i))^2$ <br> 
平方误差损失函数最小化的是预测值和真实值之间的差异，是回归问题中常见的损失函数。平方误差损失函数是**最小二乘法**的损失函数，用于衡量模型的拟合程度。
* 关于损失函数前面的系数$\frac{1}{2N}$，是为了方便求导，使得求导后的结果为$\frac{1}{N}(Y_i - f(X_i))$，这样在梯度下降中更新参数时，不用再除以N，可以直接乘以学习率，我有时写漏，但是coding时要加上。
* 美团问题：**对于分类问题为什么不用平方误差损失而用交叉熵损失**。首先在分类问题中均方误差所构造出来的损失函数是**非凸的**，不容易求解，容易得到其局部最优解；而交叉熵的损失函数是凸函数； 其次在深度学习任务中，均方误差作为**损失函数，求导后，梯度与激活函数sigmoid的导数有关，会导致训练慢**；而交叉熵的损失函数求导后，梯度就是一个差值，误差大的话更新的就快，误差小的话就更新的慢点。关于第二点具体可以参考[这里](https://zhuanlan.zhihu.com/p/104130889)。
### 2.5 绝对值误差损失函数
绝对值误差损失函数：$L(Y,f(X)) = \frac{1}{N} \sum_{i}|Y_i - f(X_i)|$ <br>
绝对值误差损失函数是回归问题中常见的损失函数，用于衡量模型的拟合程度。绝对值误差损失函数是**L1正则化**的损失函数，用于衡量模型的稳定性。
* pytorch里还有一个SmoothL1Loss(Huber Loss),介于L1和L2之间，其定义如下,即**在误差项在-1到1时是L2损失其他时候是L1损失**：
* $L_{smooth}(Y,f(X)) = \frac{1}{N} \sum_{i} \begin{cases} 0.5(y_i-f(x_i))^2 & |y_i-f(x_i)| < 1 \\ |y_i-f(x_i)| - 0.5 & |y_i-f(x_i)| \geq 1 \end{cases}$
* smoothL1本质上是小误差用MSE保证模型光滑稳定；大误差用MAE，降低outlier的影响，这个1是一个超参数可调。

### 2.6 指数损失函数
指数损失函数：$L(Y,f(X)) = \exp(-Yf(X))$ <br>
指数损失函数是Adaboost中用到的损失函数，模型预测准确时小于1；模型预测错误时大于1。它作为一个损失函数，具有**加权的性质**，即对错误分类的样本给予更大的惩罚。 <br>
指数损失函数的梯度为：$\nabla L(Y,f(X)) = -Y \exp(-Yf(X))$，因此在梯度下降中更新参数时，可以直接乘以学习率。 <br>
关于adaboost，参见[这里](ml_supervised_2.md#611-adaboost1997年的经典算法) <br>

### 2.7 损失函数和风险函数/期望损失的关系，监督学习的目标
损失函数Loss Function：$L(Y,f(X))$，**风险函数Risk Function又名期望损失Expected Loss**：$E[L(Y,f(X))]$ 在监督学习时我们希望风险函数最小，但是X和Y的联合分布是未知的，所以只能用有限的训练集样本估计风险函数，即经验风险最小化。 <br>
监督学习的目标是**经验风险最小化：$R_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i))$，其中L为损失函数，N为样本数。 <br>**
经验风险函数$R_emp(f)$和期望风险函数$R_exp(f)$的关系:当N趋于无穷时，$R_{emp}(f) \rightarrow R_{exp}(f)$，即经验风险最小化等价于期望风险最小化，很柏拉图。 <br>

### 2.8 梯度下降方法，包括批量梯度下降，随机梯度下降，小批量梯度下降
三种方法的不同在于每次更新参数用的样本选择不同。 对于一个损失函数$L(\theta)$，梯度下降的更新公式为：$\theta = \theta - \eta \nabla L(\theta)$，其中$\eta$为学习率。 $\theta$为模型参数 <br>
**批量梯度下降Batch Gradient Descent**：每次更新参数时，用所有样本计算梯度，即$\nabla L(\theta) = \frac{1}{N} \sum_{i=1}^{N} \nabla L(\theta)$，计算量大，但是稳定，收敛速度慢。 <br>
**随机梯度下降Stochastic Gradient Descent**：每次更新参数时，用一个样本计算梯度，即$\nabla L(\theta) = \nabla L(\theta)$，计算量小，但是不稳定，收敛速度快。 <br>
**小批量梯度下降Mini-batch Gradient Descent**：每次更新参数时，用一批样本计算梯度，m=batch_size，即$\nabla L(\theta) = \frac{1}{m} \sum_{i=1}^{m} \nabla L(\theta)$，折中了批量梯度下降和随机梯度下降的优缺点。 <br>


## 3. Train/Test Error Overfitting/Underfitting Regularization Generalization
### 3.1 Train Error和Test Error
**训练误差Train Error**：模型在训练集上的误差，用于衡量模型在训练集上的拟合程度。训练误差就是经验风险函数，即$E_{train} = R_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i))$,N为训练集样本数 <br>
**测试误差Test Error**：模型在测试集上的误差，$E_{test} = R_{emp}(f) = \frac{1}{M} \sum_{i=1}^{M} L(y_i,f(x_i))$, M为测试集样本数。 <br> 
* 关于Train Error的误区：训练误差大小只能判断一个问题**是否容易学习**，不能判断模型的泛化能力，测试误差才是判断模型泛化能力的标准。
### 3.2 过拟合Overfitting和欠拟合Underfitting，模型选择
过拟合学废了，欠拟合没学到。<br>
**过拟合Overfitting**：模型在训练集上表现很好，但是在测试集上表现很差，即训练误差远小于测试误差。过拟合的原因是模型过于复杂，学习到了训练集的噪声。 <br>
**欠拟合Underfitting**：模型在训练集和测试集上表现都很差，即训练误差和测试误差都很大。欠拟合的原因是模型过于简单，无法拟合训练集。 <br>
**奥卡姆剃刀原则**，在保证模型拟合训练集的情况下，选择最简单的模型。具体方法包括交叉验证和正则化。 <br>
* 如何解决Overfitting：dropout、regularization、batch normalization、early stopping <br>
* 如何解决Underfitting：增加模型复杂度、增加特征、(提高模型复杂度/减少正则化系数) <br>

### 3.3 正则化Regularization
**正则化/结构风险最小化**：$R_{struc}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i)) + \lambda J(f)$，其中J(f)为模型的复杂度，$\lambda$为正则化系数。 <br>
和上述的经验风险最小化不同，结构风险最小化在经验风险最小化的基础上加上了模型的复杂度，**在保证模型拟合训练集的情况下，选择最简单的模型**，具体是加入了$J(f)$，即对模型的惩罚，定义为一个泛函。 <br>
常见的正则化方法有L1正则化和L2正则化。L1正则化是指$J(f) = ||w||_1$，L2正则化是指$J(f) = 1/2||w||_2^2$，其中w为模型的参数。 <br>
**L0正则化**：$L0(w) = \lambda \sum_{i}I(w_i \neq 0)$，**L0是向量中非0元素的个数，效果同L1**，不用L0而用L1是因为L0的优化是NP-Hard的，L1是L0的最优凸近似。 <br>
**L1正则化**：$L1(w) = \lambda \sum_{i}|w_i|$，L1正则化可以使得模型的参数稀疏，即有些参数为0，适**用于特征选择**。又名稀疏特征算子（Lasso Regularization） <br>
**L2正则化**：$L2(w) = \lambda \sum_{i}w_i^2$，L2正则化可以使得模型的参数分布在一个范围内，适用于**防止过拟合**。又名岭回归 <br>
* Lp正则化就是模型参数的p范数，关于Lp正则化的选择，L1正则化适用于特征选择，L2正则化适用于防止过拟合，**L1和L2正则化的组合称为弹性网络（Elastic Net）**，结合了L1L2的好处。
* 关于L1为什么稀疏，L2为什么防止过拟合，可以参考[这里](https://www.cnblogs.com/weizc/p/5778678.html)。
* 百度问过L1和L2的先验分布，L1是拉普拉斯分布，L2是高斯分布，具体可参考[这里](https://zhuanlan.zhihu.com/p/344592019)。我反正看不懂原理。

### 3.4 泛化能力Generalization 泛化误差上界
**泛化能力Generalization**：模型在未知数据上的表现能力，泛化能力好的模型在新的数据上预测能力良好。可用测试误差来评价，但是过于依赖测试数据集。因此可定义 **泛化误差==期望损失函数**：$R_{exp}(f) = E[L(Y,f(X))]$，即模型在所有可能的数据上的误差；如果对于模型f1和f2，有$R_{exp}(f1)>R_{exp}(f2)$那么说明f2的泛化性能比f1好。 <br>
**泛化误差上界**：由于泛化误差未知，用泛化误差上界来估计泛化误差，泛化误差上界定理可以估计泛化误差的上界，证明方法见李航书P25-P27（过程不可能问的，问了就是难为不打算发offer）。只需要知道泛化误差上界是样本容量和假设空间的函数；样本容量越大，泛化误差上界越小（好理解，大数定律）；假设空间容量越大，模型越复杂越难学，泛化误差上界越大。 <br>
* 美团问过**训练不收敛怎么办**，md还能怎么办，要是都收敛我们就全失业了。
* 从数据角度： 是否对数据进行了预处理，包括分类标注是否正确，数据是否干净；是否对数据进行了归一化；考虑样本的信息量是否太大，而网络结构是否太简单；考虑标签是否设置正确
* 从模型角度： 尝试加深网络结构； Learning rate是否合适（太大，会造成不收敛，太小，会造成收敛速度非常慢）；错误初始化网络参数；train loss 不断下降，test loss不断下降，说明网络仍在学习; train loss 不断下降，test loss趋于不变，说明网络过拟合; train loss 趋于不变，test loss不断下降，说明数据集100%有问题; train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目; train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。

## 4. 评价指标，如准确率，精确率，召回率，F1，ROC-AUC等
这个李航书上也没有，李航是默认大家都是超天才，这部分参考瓜书。 <br>
TP、FP、TN、FN分别表示真正例、假正例、真负例、假负例。 准确率是最符合我们常识的，P和R是相对应的。F1是混合指标。<br>
### 4.1 准确率Accuracy
准确率Accuracy：$ACC = \frac{TP+TN}{TP+TN+FP+FN}$，即**预测正确的样本数占总样本数的比例**。 <br>
### 4.2 精确率Precision
精确率Precision：$P = \frac{TP}{TP+FP}$，即**预测为正例的样本中真正例的比例**。 <br>
### 4.3 召回率Recall
召回率Recall：$R = \frac{TP}{TP+FN}$，即**真正例中预测为正例的比例**。 <br>
### 4.4 F1 Score
F1 Score：$F1 = \frac{2*P*R}{P+R}$，即**精确率和召回率的调和平均数**。 <br>
### 4.5 四种指标的常见应用场景，错分类代价
**准确率**：适用于**正负样本比例相近**的情况。（如果有100个样本99个正例子1个反例子，那么分类器只要一直判断正例子，这个分类器无疑比较离谱，但是他的Acc很高，因此Acc不擅长处理样本不平衡的情况） <br>
**精确率** 当反例被错误预测成正例（FP）的代价很高时，适合用精确率。
**召回率**：**当正例被错误的预测为反例（FN）产生的代价很高时，适合用召回率**。根据公式可知，召回率越高，FN越小。如**癌症检测**，反例是癌症患者，**FN是没检测出癌症**，这个代价是很高的，召回律的场景可以记成：宁可错不能漏。 <br>
**F1 Score**：**当FN和FP的代价差别很大时，适合用F1 Score**。F1 Score是精确率和召回率的调和平均数，当FN和FP的代价差别很大时，F1 Score会更好的评价模型的性能。 <br>

### 4.6 AUC-ROC曲线
ROC曲线是以**真正例率（Recall）为纵轴，假正例率（FPR）为横轴**，AUC是ROC曲线下的面积，AUC的取值范围在0.5-1之间，AUC越大，模型的性能越好。 <br>
曲线下面积AUC：AUC是ROC曲线下的面积，AUC的取值范围在0.5-1之间，AUC越大，模型的性能越好。AUC=0.5说明模型在抛硬币。AUC在0.7-0.9是可以接受的。 <br>