# 动调实习第四周记录
## 本周计划
1. 尝试使用深度学习模型
2. 学习因果推断类模型，uplift
## 5月6日
### 1. 学习uplift模型
Uplift models用于预测一个treatment的增量反馈价值，Uplift models预测增量值，也就是lift的部分。<br>
$lift = P(buy | treatment)-P(buy | no treatment)$ <br>
由于不能同时观测到对同一个用户对这两个值和（一个用户无法同时被干预+不干预），可以通过子人群的增益效果来推断个体的增益效果。
### 2. 将训练数据集分为工作日和非工作日两个子集进行训练
1. 通过对工作日和非工作日的划分，分别选择特征，训练两个lgb模型
2. 结果：虽然工作日/非工作日的ar随时间有明显差异，但是树模型性能未有显著提升。
详细情况：<br>
使用最近14天为test，不选择特征，分别训练模型，性能如下： mae:0.010 auc:0.713 wmape:0.012 <br>
使用最近14天为test，分别选择特征后训练模型，性能如下：mae:0.005 auc:0.725 wmape:0.007 <br>
使用最近7天为test，不选择特征，分别训练模型，性能如下：mae:0.008 auc:0.723 wmape:0.011 <br>
使用最近7天为test，选择特征，分别训练模型，性能如下：mae:0.008 auc:0.723 wmape:0.011 (结果和上面没区别）<br>


## 5月7日
### 深度学习模型训练框架
预计先做一版简单的框架，基于pytorch的，后面网络结构什么再优化，先上全连接网络，写好读取训练测试储存。

## 5月8日
深度学习模型的性能如下：auc= 0.6986121388300464 mae= 0.16812654 wmape= 0.1928229

## 5月9日
目前的深度学习模型采用32x32全连接网络，使用adam优化器，学习率0.01，batch_size=20000，训练轮数500，比较粗糙。主要优化目标如下：<br>
1. 将时间变量embedding放入，因为之前画图发现时间变量对模型影响较大
2. 使用dropout防止过拟合，dropout还能加速训练，对于没gpu的机子很重要
3. 和树模型不同，深度学习模型对样本的均衡要求高，需要处理样本不均衡的问题
4. 添加l1， l2 正则防止过拟合，不过目前应该不是急着要，模型明显还没拟合
目前实现了上述的 4，模型性能如下：mae:0.125 auc:0.702 wmape:0.154

## 总结：
本周主要工作：<br>
1. 学习了uplift模型的基本概念和实现方法
2. 实现了深度学习模型的基本框架，并且auc达到了0.702，仍然有上升空间
下一周的计划：<br>
1. 继续学习uplift模型
2. 优化目前的深度学习模型，目前的网络结构比较粗糙，并且对数据的处理可能也不够