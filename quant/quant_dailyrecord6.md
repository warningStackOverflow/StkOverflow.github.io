front matter:
    --- 
    layout:default
    --- 
# week-6 target
1. 先完成单因子ic的奖励，包括因子池设计（1重写failure_cache 2 添加计算因子和已有因子相似度的方法 3 训练一轮1000 4 添加计算逐股ic方法）
2. 添加异常值检测方法：clip到0.01-0.99分位数或者 mean+-5std(不用3std因为金融数据分布更狂野)
3. 添加新的算子：前向时序rank，前向单因子自相关性，前向因子互相关
4. 后期：自动化简表达式，对接蔷薇数据接口； 异常值NaN处理； 调用LLM接口进行因子评价（这个可以适当提前，如果新算子我不会写）
5. 九月初有一个中期分享，准备一下。

# 2025/08/25
上午面试请假半天。<br>
下午在上证1000上进行单因子评估池的训练，修复当日刚入的股票前一日没有数据导致nan的问题。<br>

# 2025/08/26
(1) 完成目标1，在上证1000上进行训练 <br>
(2) 解决训练时出现梯度爆炸的问题：原因是计算奖励时会有无穷大，在更新策略的梯度时，计算$J(\theta) = E_{\pi_\theta}[G_t]$时导致无法有效训练。排查发现，r的计算是因子的ic，当生成的因子太低效，
如过于接近一个常数，波动太小，会导致计算ic时分母为0，导致ic无穷大。之前的mask方法是若std(x) or std(y)<1e-3则mask掉，但是那是对截面因子的，后来要算时序的因子的overallic，把这个条件去掉防止ic计算不准，现在将其改为1e-6的阈值<br>
(3) 改善了pool的效果，计算奖励时添加一个随机扰动。<br>
(4) 挂一个隔夜的实验，明天查看效果。 <br> 

# 2025/08/27
(1) 训练速度比之前快，但是会生成一些不应该生成的表达式，比如log中的元素小于0，似乎还可以算出ic，这是不对的，需要找改。如果修改过于不便，应该继续用pool方法，但是在reward中加入惩罚
(2) 长因子的现象应该是被抑制住了。

# 2025/08/28 
## 检查训练结果，发现因子表现不佳。
检查发现原来的计算pool中奖励的方法返回的是batch_personr（截面ic）的均值除方差。这种形式会稳定很多 <br>
## 添加llm接口
发现调用api的两种方式，1是上openai官网，要钱。 2是看有没有公司接口

# 2025/08/29
线下last day，后面开始转线上。 <br>
当前任务： <br>
（1）使用by_stock的评价指标作为奖励。 <br>
（2）训练时如果全市场显存不够，可以尝试拼接沪深300，中证500和1000，用1800只训练。 <br>
（3）考虑能否有其他的强化学习方法进行优化，比如换算法或者换网络。 <br>
（4）LLM接口是可行的，但是接openai的需要收费，可以试试deepseek。<br>